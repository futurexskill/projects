# -*- coding: utf-8 -*-
"""text_classifier_pytorch.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1US4RCI5etoX9jW5MEVveqiyUK90AIuxo
"""

import nltk

nltk.download('all')

import numpy as np
import pandas as pd

dataset = pd.read_csv('https://raw.githubusercontent.com/futurexskill/ml-model-deployment/main/Restaurant_Reviews.tsv.txt', delimiter= '\t', quoting = 3)

dataset.head()

from nltk.corpus import stopwords

from nltk.stem.porter import PorterStemmer

ps = PorterStemmer()

dataset.info()

corpus = []

import re

for i in range(0, 1000):

  customer_review = re.sub('[^a-zA-Z]', ' ',dataset['Review'][i])
  customer_review = customer_review.lower()
  customer_review = customer_review.split()
  clean_review = [ps.stem(word) for word in customer_review if not word in set(stopwords.words('english'))]
  clean_review = ' '.join(clean_review)
  corpus.append(clean_review)

corpus[0]

corpus[6]

corpus[12]

from sklearn.feature_extraction.text import TfidfVectorizer
vectorizer = TfidfVectorizer(max_features = 1500, min_df = 3, max_df = 0.6)

X = vectorizer.fit_transform(corpus).toarray()

X

X[0]

y = dataset.iloc[:, 1].values

y

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)

import torch
import torch.nn as nn
from torch.nn import functional as F

Xtrain_ = torch.from_numpy(X_train).float()
Xtest_ = torch.from_numpy(X_test).float()

ytrain_ = torch.from_numpy(y_train)
ytest_ = torch.from_numpy(y_test)

Xtrain_.shape, ytrain_.shape

Xtest_.shape, ytest_.shape

input_size=467
output_size=2
hidden_size=500

class Net(nn.Module):
   def __init__(self):
       super(Net, self).__init__()
       self.fc1 = torch.nn.Linear(input_size, hidden_size)
       self.fc2 = torch.nn.Linear(hidden_size, hidden_size)
       self.fc3 = torch.nn.Linear(hidden_size, output_size)


   def forward(self, X):
       X = torch.relu((self.fc1(X)))
       X = torch.relu((self.fc2(X)))
       X = self.fc3(X)

       return F.log_softmax(X,dim=1)

model = Net()

import torch.optim as optim
optimizer = torch.optim.Adam(model.parameters(), lr=0.01)
loss_fn = nn.NLLLoss()

epochs = 100

for epoch in range(epochs):
  optimizer.zero_grad()
  Ypred = model(Xtrain_)
  loss = loss_fn(Ypred,  ytrain_)
  loss.backward()
  optimizer.step()
  print('Epoch',epoch, 'loss',loss.item())

sample = ["Good batting by England"]

sample = vectorizer.transform(sample).toarray()

sample

torch.from_numpy(sample).float()

sentiment = model(torch.from_numpy(sample).float())
sentiment

sample2 = ["bad performance by India in the match"]

sample2 = vectorizer.transform(sample2).toarray()

sentiment2 = model(torch.from_numpy(sample2).float())
sentiment2

model.state_dict()

torch.save(model.state_dict(),'text_classifier_pytorch')

!ls

from google.colab import files

files.download('text_classifier_pytorch')

import pickle

with open('tfidfmodel.pickle','wb') as file:
    pickle.dump(vectorizer,file)

files.download('tfidfmodel.pickle')

