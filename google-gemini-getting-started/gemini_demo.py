# -*- coding: utf-8 -*-
"""gemini_demo.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HE5dmoXZ6M3cgqYLw6T2tsQCwNNVykgl
"""

!pip install -q -U google-generativeai

import google.generativeai as genai

from google.colab import userdata

GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')


genai.configure(api_key=GOOGLE_API_KEY)

model = genai.GenerativeModel('gemini-pro')

response = model.generate_content("Summarize last week's world stock market performance ")
print(response.text)

for m in genai.list_models():
  if 'generateContent' in m.supported_generation_methods:
    print(m.name)

from IPython.display import display
from IPython.display import Markdown
import textwrap

def to_markdown(text):
  text = text.replace('â€¢', '  *')
  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))

to_markdown(response.text)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# response = model.generate_content("How did the world stock market perform this week . ", stream=True)
# 
# for chunk in response:
#   print(chunk.text)
#   print("_"*80)
#

import PIL.Image

img = PIL.Image.open('sample_data/sample.jpg')
img


model = genai.GenerativeModel('gemini-pro-vision')


response = model.generate_content(img)

to_markdown(response.text)

response = model.generate_content(["Write a blog on the image", img], stream=True)
response.resolve()

to_markdown(response.text)

model = genai.GenerativeModel('gemini-pro')
chat = model.start_chat(history=[])
chat

response = chat.send_message("In one sentence, explain stock market")
to_markdown(response.text)

chat.history

response = chat.send_message("what is primary and secondary market")
to_markdown(response.text)

chat.history

response = chat.send_message("Okay, how about a more detailed explanation to a finance student", stream=True)

for chunk in response:
  print(chunk.text)
  print("_"*80)

model.count_tokens("What is stock market")

model.count_tokens(chat.history)

